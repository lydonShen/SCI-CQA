<!-- The official repository of the paper named 'Rethinking Comprehensive Benchmark for Chart Understanding: A Perspective from Scientific Literature' -->

#  Rethinking Comprehensive Benchmark for Chart Understanding: A Perspective from Scientific Literature


<h5 align="center"> If you like our project, please give us a star ‚≠ê on GitHub for latest update. 

## üì∞ News
- 24-09-05. We release the test set and validation set of SCI-CQA, which can be downloaded at HF.



# ‚≠êÔ∏è Motivation

<p align="center">
    <img src="assets/overview.png"  style="margin-bottom: 0.2;"/>
<p>

SCI-CQA address the limitations of current benchmarks and provide a more robust framework for evaluating the chart understanding abilities of multimodal models in scientific literature contexts.

- ‚ú® SCI-CQA highlights flowcharts, a crucial yet often overlooked chart type in scientific literature, addressing the gap in existing benchmarks that primarily focus on simpler chart types.
- ‚ú® By using real-world scientific charts with intricate visual elements, SCI-CQA offers a more accurate assessment of multimodal models, addressing the shortcomings of existing benchmarks that rely on overly simplistic elements.
- ‚ú® SCI-CQA introduces an evaluation framework inspired by human exams, featuring 5,629 carefully curated questions that include both objective and open-ended formats, enhancing the assessment of model understanding beyond simplistic templates.
- ‚ú® The benchmark emphasizes the importance of contextual information in chart understanding, demonstrating how context can help answer previously unanswerable questions, thereby setting a new standard for evaluating multimodal models.
- ‚ú® A new annotation pipeline is proposed that significantly reduces the costs associated with data annotation, making the process more efficient and scalable.



# üìà Dataset 

SCI-CQA will be released in this Link üîó [SCI-CQA](https://huggingface.co/datasets/lyndons1/SCI-CQA). 

In addition, we create a **large training dataset of chart understanding**, which will be published soon.



# ‚öôÔ∏è Evaluation
### Testing the open source modelÔºàUse LLaVA as an exampleÔºâ

**chartllama_experiment.py** and **llava_experiment.py** in the LLaVA folder give sample scripts for testing the open source model, which you can follow to adapt to your model.

    CUDA_VISIBLE_DEVICES=1 python -m llava.eval.model_vqa_lora --model-path /home/data_sld/chartllama_lora \
      --question-file ./data/multi-choice.json \
      --image-folder ./images/charts/ \
      --answers-file answer.jsonl \
      --num-chunks $CHUNKS \
      --chunk-idx $IDX \
      --temperature 0 \
      --conv-mode vicuna_v1 &
      
### Testing the private model modelÔºàUse GPT-4o as an exampleÔºâ

To use the following script, you need an **API-KEY** to make private model works.

    python tools/gpt4_api_evl.py 

# üõ†Ô∏è Tools
Our data collection code is also published, if you plan to collect data in another area (maybe biomedicine
chemistry and so on), you can try our methods.

### Download Latex source file

    python /tools/down_papers.py
    
### Collect scientific literature

    python /tools/fetch_papers.py

### Get Arxiv URL of scientific literature

    python /tools/get_arxiv_links.py

### Extract images and their corresponding context and captions from LaTeX source files.

    python /tools/process_papers.py

# üôè Acknowledgement

We thank the following excellent works: [CharXiv](https://github.com/princeton-nlp/CharXiv), [ChartQA](https://arxiv.org/abs/2203.10244), and [ChartAst](https://github.com/OpenGVLab/ChartAst), [LLaVA](https://llava-vl.github.io/).

SCI-CQA is inspired by previous excellent works, and we are standing on the shoulders of giants for further exploration.



# üìí License
* The majority of this project is released under the Apache 2.0 license as found in the [LICENSE](https://github.com/ShawnHuang497/BiRD/blob/main/LICENSE) file.
* The service is a research preview intended for non-commercial use only, subject to [Terms of Use](https://openai.com/policies/terms-of-use) of the data generated by OpenAI.
* Since all of our charts are from illustrations in the scientific literature, the original authors own the copyright.
* Please contact us if you find any potential violation.


# ü´° Citation
If you find our paper and code useful in your research, please consider giving a star or citation.

```BibTeX

```
